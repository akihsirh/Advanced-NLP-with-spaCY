{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are statistical models?\n",
    "Enable spaCy to predict linguistic attributes in context\n",
    "- Part-of-speech tags\n",
    "- Syntactic dependencies\n",
    "- Named entities\n",
    "\n",
    "Statistical models enable spaCy to make predictions in context. This usually includes part-of speech tags, syntactic dependencies and named entities.\n",
    "\n",
    "Models are trained on large datasets of labeled example texts. They can be updated with more examples to fine-tune their predictions – for example, to perform better on your specific data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Packages\n",
    "\n",
    "spaCy provides a number of pre-trained model packages that can be downloaded using the \"spacy download\" command. One such package is the \"en_core_web_sm\" package. This is a small English model that supports all core capabilities and is trained on text from the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the load method to load the model package by name. The method call returns an nlp object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package comes with a pre-trained model that contains binary weights that enable spaCy to make predictions.\n",
    "\n",
    "It also includes the vocabulary, and meta information to tell spaCy which language class to use and how to configure the processing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting part-of-speech tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy can be used to predict part-of-speech tags using the pos_ attribute. \n",
    "\n",
    "In spaCy, attributes that return strings usually end with an underscore. Attributes without the underscore return an ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"She ate the pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She PRON\n",
      "ate VERB\n",
      "the DET\n",
      "pizza NOUN\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Syntactic Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spacy model can also be used to predict how the words are related. \n",
    "- The \"dep underscore\" attribute returns the predicted dependency label.\n",
    "- The head attribute returns the syntactic head token or in other words the parent token this word is attached to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She PRON nsubj ate\n",
      "ate VERB ROOT ate\n",
      "the DET det pizza\n",
      "pizza NOUN dobj ate\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To describe syntactic dependencies, spaCy uses a standardized label scheme.\n",
    "- The pronoun \"She\" is a nominal subject attached to the verb – in this case, to \"ate\".\n",
    "- The noun \"pizza\" is a direct object attached to the verb \"ate\". It is eaten by the subject, \"she\".\n",
    "- The determiner \"the\", also known as an article, is attached to the noun \"pizza\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It PRON nsubj ’s\n",
      "’s VERB compound official\n",
      "official NOUN ROOT official\n",
      ": PUNCT punct official\n",
      "Apple PROPN nsubj is\n",
      "is AUX ROOT is\n",
      "the DET det company\n",
      "first ADJ amod company\n",
      "U.S. PROPN nmod company\n",
      "public ADJ amod company\n",
      "company NOUN attr is\n",
      "to PART aux reach\n",
      "reach VERB relcl company\n",
      "a DET det value\n",
      "$ SYM quantmod trillion\n",
      "1 NUM compound trillion\n",
      "trillion NUM nummod value\n",
      "market NOUN compound value\n",
      "value NOUN dobj reach\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Named Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named entities are \"real world objects\" that are assigned a name – for example, a person, an organization or a country.\n",
    "\n",
    "The ents property on a document object lets you access the named entities predicted by the model.\n",
    "\n",
    "It returns an iterator of Span objects, so we can print the entity text and the entity label using the label/label_ attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 383\n",
      "U.K. 384\n",
      "$1 billion 394\n"
     ]
    }
   ],
   "source": [
    "# Process a text\n",
    "doc = nlp(u\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "# Iterate over the predicted entities\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting named entities in context\n",
    "\n",
    "Models are statistical and not always right. Whether their predictions are correct depends on the training data and the text you’re processing. In the below example the model does not recognise Iphone X as an entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 383\n",
      "Missing entity: iPhone X\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"New iPhone X release date leaked as Apple reveals pre-orders by mistake\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the entities\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and label\n",
    "    print(ent.text, ent.label)\n",
    "\n",
    "# Get the span for \"iPhone X\"\n",
    "iphone_x = doc[1:3]\n",
    "\n",
    "# Print the span text\n",
    "print(\"Missing entity:\", iphone_x.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The explain method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick tip: spacy.explain can be used to get definitions for the most common tags and labels. The same works for part-of-speech tags and dependency labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'direct object'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('dobj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun, proper singular'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('NNP')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
