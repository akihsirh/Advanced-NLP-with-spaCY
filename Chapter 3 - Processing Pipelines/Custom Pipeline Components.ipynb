{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom pipeline components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCY lets you add your own function to it's inbuilt pipeline. These added in components are executed automatically when you call the nlp object on a text. You can even add your own metadata to documents and tokens and update built-in attributes.\n",
    "\n",
    "Components can be added to the pipeline using the nlp.add_pipe method which takes the component you want to add as a  parameter. Position in the pipeline can be specified by passing:\n",
    "- Boolean values to the function: first= True last = True\n",
    "- Specifying explicitly where you want to execute the custom component wrt spaCY's inbuilt component: before=\"ner\", after=\"tagger\". If the specified component does not exist, spaCY will raise an error.\n",
    "\n",
    "**Note**: Custom components are added to the pipeline after the language class is already initialized and after tokenization. They are can also only modify the Doc and canâ€™t be used to update weights of other components directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple component Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tagger', 'parser', 'ner', 'length_component']\n",
      "This document is 2 tokens long.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Define the custom component\n",
    "def length_component(doc):\n",
    "    # Get the doc's length\n",
    "    doc_length = len(doc)\n",
    "    print(\"This document is {} tokens long.\".format(doc_length))\n",
    "    # Return the doc\n",
    "    return doc\n",
    "\n",
    "\n",
    "# Load the small English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Add the component first in the pipeline and print the pipe names\n",
    "nlp.add_pipe(length_component)\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "# Process a text\n",
    "doc = nlp(\"Short sentence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex component example\n",
    "\n",
    "Create a custom component that uses the PhraseMatcher to find animal names in the document and adds the matched spans to the doc.ents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potter characters: [Harry Potter, Ron Weasley, Hermione Granger]\n",
      "['tagger', 'parser', 'ner', 'harry_potter_people']\n",
      "[('Harry Potter', 4957663859231939894), ('Hermione Granger', 4957663859231939894)]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "characters = [\"Harry Potter\", \"Ron Weasley\", \"Hermione Granger\"]\n",
    "potter_patterns = list(nlp.pipe(characters))\n",
    "print(\"Potter characters:\", potter_patterns)\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "matcher.add(\"POTTER\", None, *potter_patterns)\n",
    "\n",
    "# Define the custom component\n",
    "def harry_potter_people(doc):\n",
    "    # Apply the matcher to the doc\n",
    "    matches = matcher(doc)\n",
    "    # Create a Span for each match and assign the label 'ANIMAL'\n",
    "    spans = [Span(doc, start, end, label=match_id) for match_id, start, end in matches]\n",
    "    # Overwrite the doc.ents with the matched spans\n",
    "    doc.ents = spans\n",
    "    return doc\n",
    "\n",
    "\n",
    "# Add the component to the pipeline after the 'ner' component\n",
    "nlp.add_pipe(harry_potter_people, after=\"ner\")\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "# Process the text and print the text and label for the doc.ents\n",
    "doc = nlp(\"Harry Potter and Hermione Granger are a couple ? Impossible!\")\n",
    "print([(ent.text, ent.label) for ent in doc.ents])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
